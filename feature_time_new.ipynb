{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from os import remove\n",
    "\n",
    "path = ''\n",
    "\n",
    "file = path+\"train_data.csv\"\n",
    "file_te = path+\"test_data.csv\"\n",
    "outputhead = 'feat_1hr.v3.'\n",
    "daycut_val = pd.to_datetime(pd.Series(['2016-06-01','2016-06-24'])).map(lambda x: x.date()) \n",
    "daycut_tr = pd.to_datetime(pd.Series(['2016-05-06','2016-05-31'])).map(lambda x: x.date())\n",
    "daycut_Rtr = pd.to_datetime(pd.Series(['2016-06-05','2016-06-30'])).map(lambda x: x.date())\n",
    "\n",
    "valdays = 31\n",
    "lastday = 182\n",
    "daycut_agg = np.array([0, lastday-valdays]) #M1-M5\n",
    "\n",
    "divide = 3600. * 1 #for 1 hours\n",
    "\n",
    "try:\n",
    "    remove(path+outputhead+'train.h5')\n",
    "    remove(path+outputhead+'test.h5')\n",
    "    print('file '+path+outputhead+'train.h5 removed!')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load data\n",
    "df_train = pd.read_csv(file, usecols = ['custid','platform','currency',\n",
    "                                        'groupid','timestamp','invest'])#,nrows=1000000)\n",
    "days = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add time of day column\n",
    "mintimestamp = np.min(df_train['timestamp'])\n",
    "timestamp = df_train['timestamp'] - mintimestamp\n",
    "divide = 3600. #for 1 hours\n",
    "df_train['time_hr'] = (np.rint(np.remainder(timestamp, 3600*24)/(divide)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby currency, time\n",
    "grouped2 = df_train[ (df_train['invest']>=2.0) & (df_train['invest'] < 10.0)].\\\n",
    "           groupby(['currency','time_hr'])\n",
    "grouped10 = df_train[df_train['invest']>=10.0].groupby(['currency','time_hr'])\n",
    "grouped = df_train.groupby(['currency','time_hr'])\n",
    "bin_hr_currency = pd.DataFrame({'meanInv.curHr': grouped['invest'].mean().round(decimals=2), \n",
    "'rInvGT2.curHr':(grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT10.curHr':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "'q75Inv.curHr':grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "'q95Inv.curHr':grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "'q999Inv.curHr':grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby platform, time\n",
    "grouped2 = df_train[(df_train['invest']>=2.0) & (df_train['invest'] < 10.0)].\\\n",
    "groupby(['platform','time_hr'])\n",
    "grouped10 = df_train[df_train['invest']>=10.0].groupby(['platform','time_hr'])\n",
    "grouped = df_train.groupby(['platform','time_hr'])\n",
    "bin_hr_pltf = pd.DataFrame({'meanInv.pltfHr': grouped['invest'].mean().round(decimals=2), \n",
    "'rInvGT2.pltfHr':(grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT10.pltfHr':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "'q75Inv.pltfHr':grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "'q95Inv.pltfHr':grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "'q999Inv.pltfHr':grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby groupid, time_hr\n",
    "grouped2 = df_train[(df_train['invest']>=2.0) & (df_train['invest'] < 10.0)].\\\n",
    "groupby(['groupid', 'time_hr'])\n",
    "grouped10 = df_train[df_train['invest']>=10.0].groupby(['groupid','time_hr'])\n",
    "grouped = df_train.groupby(['groupid', 'time_hr'])\n",
    "bin_hr_grpid = pd.DataFrame({'meanInv.grpidHr': grouped['invest'].mean().round(decimals=2), \n",
    "'rInvGT2.grpidHr':(grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT10.grpidHr':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "'q75Inv.grpidHr':grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "'q95Inv.grpidHr':grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "'q999Inv.grpidHr':grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()\n",
    "\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get test data, use it to filter the train data, and merge. \n",
    "df_train = pd.read_csv(file, usecols = ['custid','eventid','invest'])#,nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## custid bin can be done with this limited sample\n",
    "\n",
    "## groupby custid\n",
    "grouped1 = df_train[(df_train['invest']>=1.5) & (df_train['invest'] < 2.0)].\\\n",
    "groupby(['custid'])\n",
    "grouped2 = df_train[(df_train['invest']>=2.0) & (df_train['invest'] < 10.0)].\\\n",
    "groupby(['custid'])\n",
    "grouped10 = df_train[(df_train['invest']>=10.0)].groupby(['custid'])\n",
    "grouped = df_train.groupby(['custid'])\n",
    "bin_custid = pd.DataFrame({'meanInv.custid': grouped['invest'].mean().round(decimals=2), \n",
    "'rInvGT1.custid': (grouped1['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT2.custid': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT10.custid':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "'q25Inv.custid':  grouped['invest'].quantile(0.25).round(decimals=2), \n",
    "'q50Inv.custid':  grouped['invest'].quantile(0.50).round(decimals=2), \n",
    "'q75Inv.custid':  grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "'q95Inv.custid':  grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "'q999Inv.custid':  grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['day'] = (np.rint(timestamp/(3600*24.)))\n",
    "\n",
    "grouped1 = df_train[(df_train['invest']>=1.5) & (df_train['invest'] < 2.0)].\\\n",
    "groupby(['eventid'])\n",
    "grouped2 = df_train[(df_train['invest']>=2.0) & (df_train['invest'] < 10.0)].\\\n",
    "groupby(['eventid'])\n",
    "grouped10 = df_train[df_train['invest']>=10.0].groupby(['eventid'])\n",
    "grouped = df_train.groupby(['eventid'])\n",
    "bin_eventid = pd.DataFrame({'cnt.eventid': grouped['invest'].count(), \n",
    "#'daycnt.eventid': len(np.unique(grouped['day'].values)),\n",
    "'rInvGT1.eventid': (grouped1['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT2.eventid': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "'rInvGT10.eventid':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "'q25Inv.eventid':  grouped['invest'].quantile(0.25).round(decimals=2), \n",
    "'q50Inv.eventid':  grouped['invest'].quantile(0.50).round(decimals=2), \n",
    "'q75Inv.eventid':  grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "'q95Inv.eventid':  grouped['invest'].quantile(0.95).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()\n",
    "\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out test result\n",
    "df_test = pd.read_csv(file_te, usecols = ['custid','currency',\\\n",
    "                                          'eventid','platform','groupid','timestamp'])\n",
    "df_test['index'] = np.arange(df_test.shape[0])\n",
    "\n",
    "timestamp = df_test['timestamp'] - mintimestamp\n",
    "df_test['time_hr'] = (np.rint(np.remainder(timestamp, 3600*24)/(divide)))\n",
    "\n",
    "df_test = df_test.merge(bin_custid,\\\n",
    "                        left_on='custid',how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_eventid,\\\n",
    "                        left_on='eventid',how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_currency,\\\n",
    "                        left_on=['custid','time_hr'], how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_pltf,\\\n",
    "                        left_on=['platform','time_hr'], how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_grpid,\\\n",
    "                        left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "\n",
    "df_test.sort_index(inplace=True)\n",
    "\n",
    "df_test.drop(['currency','platform','custid',\\\n",
    "              'eventid', 'groupid','timestamp'],axis=1,inplace=True)\n",
    "print(df_test.columns)\n",
    "print(df_test.shape) \n",
    "df_test.to_hdf(path+outputhead+'test.h5','test',format='table')\n",
    "print('df_test ouput done!')\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out train\n",
    "\n",
    "## load data\n",
    "chunksize = 40730866/5\n",
    "cols = ['custid','platform','currency', 'groupid','eventid','timestamp','invest']\n",
    "ind = 0\n",
    "nrows = 0\n",
    "print('daycut {0}--{1}'.format(daycut_Rtr[0],daycut_Rtr[1]))\n",
    "for chunk in pd.read_csv(file, usecols = cols,chunksize = chunksize):\n",
    "    chunk['index'] = np.arange(chunk.shape[0]) + nrows\n",
    "    nrows = nrows + chunk.shape[0]\n",
    "#    chunk = chunk[chunk['custid'].isin(cust)]\n",
    "\n",
    "    timestamp = chunk['timestamp'] - mintimestamp\n",
    "    chunk['timestamp'] = pd.to_datetime(chunk['timestamp'], unit='s').map(lambda x: x.date())\n",
    "\n",
    "    print('day range: ({0}, {1})'.format(chunk['timestamp'].min(), chunk['timestamp'].max()))\n",
    "    if ( (chunk['timestamp'].min() > daycut_Rtr[1]) | (chunk['timestamp'].max() < daycut_Rtr[0])): \n",
    "        print('chunk {0} ignored!'.format(ind+1))\n",
    "        ind = ind+1\n",
    "        continue\n",
    "\n",
    "    chunk = (chunk[ (chunk['timestamp'] <= daycut_Rtr[1]) & (chunk['timestamp'] > daycut_Rtr[0])] )\n",
    "    chunk['time_hr'] = (np.rint(np.remainder(timestamp, 3600*24)/(divide)))\n",
    "    \n",
    "    chunk = chunk.merge(bin_custid, left_on='custid',how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_eventid, left_on='eventid',how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_currency, left_on=['currency','time_hr'], how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_pltf, left_on=['platform','time_hr'], how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_grpid, left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "\n",
    "    chunk.set_index('index',inplace=True)\n",
    "    chunk.sort_index(inplace=True)\n",
    "    chunk.drop(['groupid','currency','custid','eventid','platform'],axis=1, inplace=True)\n",
    "\n",
    "    if(chunk['timestamp'].min() < daycut_Rtr[1]): \n",
    "        chunk_tr = chunk[(chunk['timestamp'] <= daycut_Rtr[1]) & (chunk['timestamp'] > daycut_Rtr[0])]\n",
    "        chunk_tr.drop('timestamp',axis=1,inplace=True)\n",
    "        cols = chunk.columns.tolist()\n",
    "        ncols = cols[1:]\n",
    "        ncols.append(cols[0])\n",
    "        chunk = chunk[ncols]\n",
    "        chunk_tr.to_hdf(path+outputhead+'train.h5','train', format='table', append=True)\n",
    "        print('    --- to train.h5')\n",
    "\n",
    "    cc = chunk.columns\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "    print('chunk {0} done!'.format(ind+1))\n",
    "    ind = ind + 1\n",
    "\n",
    "print('df_train output done!')\n",
    "print('{0} rows is written in total.'.format(nrows))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
