{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "path = ''\n",
    "from os import remove\n",
    "\n",
    "totallines = 40730866\n",
    "nrows = 100\n",
    "## Load data\n",
    "file = path+\"train_data.csv\"\n",
    "file_te = path+\"test_data.csv\"\n",
    "outputhead = 'feat_MACnt.dM1dVal1.'\n",
    "daycut_val = pd.to_datetime(pd.Series(['2016-06-01','2016-06-24'])).map(lambda x: x.date()) \n",
    "daycut_tr = pd.to_datetime(pd.Series(['2016-05-06','2016-05-31'])).map(lambda x: x.date())\n",
    "daycut_Rtr = pd.to_datetime(pd.Series(['2016-06-05','2016-06-30'])).map(lambda x: x.date())\n",
    "\n",
    "try:\n",
    "    remove(path+outputhead+'train.h5')\n",
    "    remove(path+outputhead+'test.h5')\n",
    "    print('file '+path+outputhead+'train.h5 removed!')\n",
    "    print('file '+path+outputhead+'test.h5 removed!')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_time = pd.read_csv(file, usecols = ['timestamp', 'custid', 'invest'])\n",
    "te_time = pd.read_csv(file_te, usecols = ['timestamp', 'custid'])\n",
    "df_time = pd.concat([df_time,te_time],axis=0, join='outer')\n",
    "del te_time\n",
    "gc.collect()\n",
    "df_time.set_index(pd.to_datetime(df_time['timestamp'], unit='s'),inplace=True)\n",
    "df_time['invest'].fillna(0, inplace=True)\n",
    "\n",
    "ts = df_time[['custid','invest']].groupby('custid')\\\n",
    "     .apply(lambda x: (x.resample('d').count().rolling(window=15,center=False).sum())) \n",
    "ts.rename(columns = {'invest': 'aMA15d_custid'}, inplace=True)\n",
    "ts.drop('custid', axis=1, inplace=True)\n",
    "\n",
    "ts['medMA15d_custid'] = ts.groupby(level=0)['aMA15d_custid'].apply(lambda x: x*0.+ np.nanmedian(x))\n",
    "ts['pMA15d_custid'] = ts.groupby(level=0)['aMA15d_custid'].shift(-15)\n",
    "ts['aMA15d_custid'] = ts.groupby(level=0)['aMA15d_custid'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts['pMA15d_custid'] = ts.groupby(level=0)['pMA15d_custid'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts['aMA5d_custid'] = df_time[['custid','invest']].groupby('custid')['invest']\\\n",
    "                     .apply(lambda x: (x.resample('d').count().rolling(window=5,center=False).sum())) \n",
    "ts['medMA5d_custid'] = ts.groupby(level=0)['aMA5d_custid'].apply(lambda x: x*0.+ np.nanmedian(x))\n",
    "ts['pMA5d_custid'] = ts.groupby(level=0)['aMA5d_custid'].shift(-5)\n",
    "ts['aMA5d_custid'] = ts.groupby(level=0)['aMA5d_custid'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts['pMA5d_custid'] = ts.groupby(level=0)['pMA5d_custid'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts['MA1d_custid'] = df_time[['custid','invest']].groupby('custid')['invest']\\\n",
    "                    .apply(lambda x: (x.resample('d').count())) \n",
    "ts['medMA1d_custid'] = ts.groupby(level=0)['MA1d_custid'].apply(lambda x: x*0.+ np.nanmedian(x[x>0]))\n",
    "ts['MA1d_custid'] = ts.groupby(level=0)['MA1d_custid'].apply(lambda x: x/np.nanmedian(x[x>0]))\n",
    "\n",
    "ts.reset_index(['custid','timestamp'],inplace=True)\n",
    "ts['timestamp'] = ts['timestamp'].map(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time = pd.read_csv(file, usecols = ['timestamp', 'currency', 'invest'])\n",
    "te_time = pd.read_csv(file_te, usecols = ['timestamp', 'currency'])\n",
    "df_time = pd.concat([df_time,te_time],axis=0, join='outer')\n",
    "del te_time\n",
    "gc.collect()\n",
    "df_time.set_index(pd.to_datetime(df_time['timestamp'], unit='s'),inplace=True)\n",
    "df_time['invest'].fillna(0, inplace=True)\n",
    "\n",
    "ts_c = df_time[['currency','invest']].groupby('currency')\\\n",
    "       .apply(lambda x: (x.resample('d').count().rolling(window=15,center=False).sum())) \n",
    "ts_c.rename(columns = {'invest': 'aMA15d_currency'}, inplace=True)\n",
    "ts_c.drop('currency', axis=1, inplace=True)\n",
    "ts_c['medMA15d_currency'] = ts_c.groupby(level=0)['aMA15d_currency'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x)))\n",
    "ts_c['pMA15d_currency'] = ts_c.groupby(level=0)['aMA15d_currency'].shift(-15)\n",
    "ts_c['aMA15d_currency'] = ts_c.groupby(level=0)['aMA15d_currency'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts_c['pMA15d_currency'] = ts_c.groupby(level=0)['pMA15d_currency'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts_c['aMA5d_currency'] = df_time[['currency','invest']].groupby('currency')['invest']\\\n",
    "                         .apply(lambda x: (x.resample('d').count().rolling(window=5,center=False).sum())) \n",
    "ts_c['medMA5d_currency'] = ts_c.groupby(level=0)['aMA5d_currency'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x)))\n",
    "ts_c['pMA5d_currency'] = ts_c.groupby(level=0)['aMA5d_currency'].shift(-5)\n",
    "ts_c['aMA5d_currency'] = ts_c.groupby(level=0)['aMA5d_currency'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts_c['pMA5d_currency'] = ts_c.groupby(level=0)['pMA5d_currency'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts_c['MA1d_currency'] = df_time[['currency','invest']].groupby('currency')['invest']\\\n",
    "                        .apply(lambda x: (x.resample('d').count())) \n",
    "ts_c['medMA1d_currency'] = ts_c.groupby(level=0)['MA1d_currency'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x[x>0])))\n",
    "ts_c['MA1d_currency'] = ts_c.groupby(level=0)['MA1d_currency'].apply(lambda x: x/np.nanmedian(x[x>0]))\n",
    "ts_c.reset_index(['currency','timestamp'],inplace=True)\n",
    "ts_c['timestamp'] = ts_c['timestamp'].map(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time = pd.read_csv(file, usecols = ['timestamp', 'platform', 'invest'])\n",
    "te_time = pd.read_csv(file_te, usecols = ['timestamp', 'platform'])\n",
    "df_time = pd.concat([df_time,te_time],axis=0, join='outer')\n",
    "del te_time\n",
    "gc.collect()\n",
    "df_time.set_index(pd.to_datetime(df_time['timestamp'], unit='s'),inplace=True)\n",
    "df_time['invest'].fillna(0, inplace=True)\n",
    "\n",
    "ts_p = df_time[['platform','invest']].groupby('platform')\\\n",
    "       .apply(lambda x: (x.resample('d').count().rolling(window=15,center=False).sum())) \n",
    "ts_p.rename(columns = {'invest': 'aMA15d_plt'}, inplace=True)\n",
    "ts_p.drop('platform', axis=1, inplace=True)\n",
    "ts_p['medMA15d_plt'] = ts_p.groupby(level=0)['aMA15d_plt'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x)))\n",
    "ts_p['pMA15d_plt'] = ts_p.groupby(level=0)['aMA15d_plt'].shift(-15)\n",
    "ts_p['aMA15d_plt'] = ts_p.groupby(level=0)['aMA15d_plt'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts_p['pMA15d_plt'] = ts_p.groupby(level=0)['pMA15d_plt'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts_p['aMA5d_plt'] = df_time[['platform','invest']].groupby('platform')['invest']\\\n",
    "                    .apply(lambda x: (x.resample('d').count().rolling(window=5,center=False).sum())) \n",
    "ts_p['medMA5d_plt'] = ts_p.groupby(level=0)['aMA5d_plt'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x)))\n",
    "ts_p['pMA5d_plt'] = ts_p.groupby(level=0)['aMA5d_plt'].shift(-5)\n",
    "ts_p['aMA5d_plt'] = ts_p.groupby(level=0)['aMA5d_plt'].apply(lambda x: x/np.nanmedian(x))\n",
    "ts_p['pMA5d_plt'] = ts_p.groupby(level=0)['pMA5d_plt'].apply(lambda x: x/np.nanmedian(x))\n",
    "\n",
    "ts_p['MA1d_plt'] = df_time[['platform','invest']].groupby('platform')['invest']\\\n",
    "                   .apply(lambda x: (x.resample('d').count())) \n",
    "ts_p['medMA1d_plt'] = ts_p.groupby(level=0)['MA1d_plt'].apply(lambda x: x*0.+ np.log10(np.nanmedian(x[x>0])))\n",
    "ts_p['MA1d_plt'] = ts_p.groupby(level=0)['MA1d_plt'].apply(lambda x: x/np.nanmedian(x[x>0]))\n",
    "\n",
    "ts_p.reset_index(['platform','timestamp'],inplace=True)\n",
    "ts_p['timestamp'] = ts_p['timestamp'].map(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(file_te, usecols = ['custid','currency','platform','timestamp'])\n",
    "df_test['index'] = np.arange(df_test.shape[0])\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'], unit='s').map(lambda x: x.date())\n",
    "\n",
    "df_test = df_test.merge(ts, on=['custid','timestamp'],how='left')\n",
    "df_test = df_test.merge(ts_c, on=['currency','timestamp'],how='left')\n",
    "df_test = df_test.merge(ts_p, on=['platform','timestamp'],how='left')\n",
    "\n",
    "df_test.set_index('index',inplace=True)\n",
    "df_test.sort_index(inplace=True)\n",
    "df_test.drop(['currency','platform','custid','timestamp'],axis=1,inplace=True)\n",
    "print(df_test.columns)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.to_hdf(path+outputhead+'test.h5','test',format='table')\n",
    "print('df_test ouput done!')\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out train\n",
    "\n",
    "## Load data\n",
    "chunksize = 40730866/5\n",
    "cols = ['timestamp','custid', 'currency','platform','invest']\n",
    "ind = 0\n",
    "nrows = 0\n",
    "print('daycut {0}--{1}'.format(daycut_Rtr[0],daycut_Rtr[1]))\n",
    "for chunk in pd.read_csv(file, usecols = cols,chunksize = chunksize):\n",
    "    chunk['index'] = np.arange(chunk.shape[0]) + nrows\n",
    "    nrows = nrows + chunk.shape[0]\n",
    "    chunk['timestamp'] = pd.to_datetime(chunk['timestamp'], unit='s').map(lambda x: x.date())\n",
    "\n",
    "    print('day range: ({0}, {1})'.format(chunk['timestamp'].min(), chunk['timestamp'].max()))\n",
    "    if ( (chunk['timestamp'].min() > daycut_Rtr[1]) | (chunk['timestamp'].max() < daycut_Rtr[0])): \n",
    "        print('chunk {0} ignored!'.format(ind+1))\n",
    "        ind = ind + 1\n",
    "        continue\n",
    "\n",
    "    chunk = (chunk[ (chunk['timestamp'] <= daycut_Rtr[1]) & (chunk['timestamp'] > daycut_Rtr[0])] )\n",
    "\n",
    "    chunk = chunk.merge(ts, on=['custid','timestamp'],how='left')\n",
    "    chunk = chunk.merge(ts_c, on=['currency','timestamp'],how='left')\n",
    "    chunk = chunk.merge(ts_p, on=['platform','timestamp'],how='left')\n",
    "\n",
    "    chunk.set_index('index',inplace=True)\n",
    "    chunk.sort_index(inplace=True)\n",
    "    chunk.drop(['currency','platform','custid'],axis=1,inplace=True)\n",
    "\n",
    "    if(chunk['timestamp'].min() < daycut_Rtr[1]): \n",
    "        chunk_tr = chunk[(chunk['timestamp'] <= daycut_Rtr[1]) & (chunk['timestamp'] > daycut_Rtr[0])]\n",
    "        chunk_tr.drop('timestamp',axis=1,inplace=True)\n",
    "        cols = chunk.columns.tolist()\n",
    "        ncols = cols[1:]\n",
    "        ncols.append(cols[0])\n",
    "        chunk = chunk[ncols]\n",
    "        chunk_tr.to_hdf(path+outputhead+'train.h5','train', format='table', append=True)\n",
    "        print('--------- to train.h5')\n",
    "\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "    print('chunk {0} done!'.format(ind+1))\n",
    "    ind = ind+1\n",
    "    \n",
    "print(chunk.columns)\n",
    "print('{0} rows is written in total.'.format(nrows))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
