{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "path = ''\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from os import remove\n",
    "totallines = 40730866\n",
    "\n",
    "valdays = 24\n",
    "dMonth = 1\n",
    "outputhead = 'feat_dM{0}dVal{1}-1hr'.format(dMonth,valdays)\n",
    "## Load data\n",
    "file = path+\"train_data.csv\"\n",
    "lastday = 182\n",
    "\n",
    "divide = 3600. * 1 #for 1 hours\n",
    "\n",
    "daycut_val = lastday - np.array([valdays,0]) \n",
    "daycut_tr = daycut_val[0] - np.array([dMonth,0])*30 #M6b\n",
    "daycut_agg = np.array([0, daycut_tr[0]])  #M1-M5\n",
    "\n",
    "daycut_Rtr = lastday - np.array([dMonth,0])*30 \n",
    "daycut_Ragg = np.array([0, daycut_Rtr[0]])\n",
    "\n",
    "# try:\n",
    "#     remove(path+'/data/'+outputhead+'train.h5')\n",
    "#     remove(path+'/data/'+outputhead+'test.h5')\n",
    "#     print('file '+path+'/data/'+outputhead+'train.h5 removed!')\n",
    "# except OSError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(file, usecols = ['custid','groupid','timestamp','invest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add time of day column\n",
    "mintimestamp = np.min(df_train['timestamp'])\n",
    "df_train['timestamp'] = df_train['timestamp'] - mintimestamp\n",
    "df_train['day'] = np.fix(df_train['timestamp'] / 3600./24.) +1\n",
    "df_train['time_hr'] = (np.rint(np.remainder(df_train['timestamp'], 3600*24)/(divide)))\n",
    "df_train = df_train[ (df_train['day'] <= daycut_agg[1]) & (df_train['day'] > daycut_agg[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby groupid, time_hr\n",
    "grouped2 = df_train[df_train['invest']>2.0].groupby(['groupid', 'time_hr'])\n",
    "grouped10 = df_train[df_train['invest']>10.0].groupby(['groupid','time_hr'])\n",
    "grouped = df_train.groupby(['groupid', 'time_hr'])\n",
    "bin_hr_grpid = pd.DataFrame({'meanInv.grpidHr': grouped['invest'].mean().round(decimals=2), \n",
    "                             'rInvGT2.grpidHr': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                             'rInvGT10.grpidHr': (grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                             'q75Inv.grpidHr': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                             'q95Inv.grpidHr': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                             'q999Inv.grpidHr': grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get test data, use it to filter the train data, and merge. \n",
    "\n",
    "## filter the df_train, and only leave the rows with the custid appeared in the test set\n",
    "\n",
    "## groupby custid\n",
    "grouped2 = df_train[(df_train['invest']>2.0)& (df_train['invest']<10.)].groupby(['custid'])\n",
    "grouped10 = df_train[(df_train['invest']>10.0) ].groupby(['custid'])\n",
    "grouped = df_train.groupby(['custid'])\n",
    "bin_custid = pd.DataFrame({'meanInv.custid': grouped['invest'].mean().round(decimals=2), \n",
    "                           'rInvGT2.custid': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                           'rInvGT10.custid': (grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                           'q75Inv.custid': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                           'q95Inv.custid': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                           'q999Inv.custid': grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby custid and time_hr\n",
    "grouped2 = df_train[(df_train['invest']>2.0)& (df_train['invest']<10.)].groupby(['custid','time_hr'])\n",
    "grouped10 = df_train[(df_train['invest']>10.0) ].groupby(['custid', 'time_hr'])\n",
    "grouped = df_train.groupby(['custid','time_hr'])\n",
    "bin_hr_custid = pd.DataFrame({'meanInv.custidHr': grouped['invest'].mean().round(decimals=2), \n",
    "                              'rInvGT2.custidHr': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                              'rInvGT10.custidHr': (grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                              'q75Inv.custidHr': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                              'q95Inv.custidHr': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                              'q999Inv.custidHr': grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = path+\"test_data.csv\"\n",
    "df_test = pd.read_csv(file, usecols = ['custid','groupid','timestamp'], nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['timestamp'] = df_test['timestamp'] - mintimestamp\n",
    "df_test['time_hr'] = (np.rint(np.remainder(df_test['timestamp'], 3600*24)/(divide)))\n",
    "df_test['index'] = np.arange(df_test.shape[0])\n",
    "\n",
    "df_test = df_test.merge(bin_custid, left_on='custid',how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_custid, left_on=['custid','time_hr'],how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_grpid, left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "df_test.set_index('index',inplace=True)\n",
    "df_test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.drop(['groupid','custid'], axis=1, inplace=True)\n",
    "df_test.to_hdf(path+outputhead+'_test.h5','test',format='table')\n",
    "print('df_test ouput done!')\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out train\n",
    "\n",
    "file = path+\"test_data.csv\"\n",
    "df_test = pd.read_csv(file, usecols = ['custid'])\n",
    "cust = np.unique(df_test['custid'])\n",
    "\n",
    "## Load data\n",
    "file = path+\"train_data.csv\"\n",
    "chunksize = 40730866/10\n",
    "cols = ['custid', 'groupid','timestamp','invest']\n",
    "ind = 0\n",
    "nrows = 0\n",
    "print('daycut {0}--{1},{2}--{3},{4}--{5}'.format(daycut_agg[0],\n",
    "      daycut_agg[1],daycut_tr[0],daycut_tr[1],daycut_val[0],daycut_val[1]))\n",
    "for chunk in pd.read_csv(file,usecols = cols,chunksize = chunksize):\n",
    "    chunk['index'] = np.arange(chunk.shape[0]) + nrows\n",
    "    nrows = nrows + chunk.shape[0]\n",
    "    chunk.set_index('index',inplace=True)\n",
    "    chunk['timestamp'] = chunk['timestamp'] - mintimestamp\n",
    "    chunk['day'] = np.fix(chunk['timestamp'] / 3600./24.) + 1\n",
    "\n",
    "    print('day range: ({0},{1})'.format(chunk['day'].min(), chunk['day'].max()))\n",
    "    if ( (chunk['day'].min() > daycut_val[1]) | (chunk['day'].max() < daycut_tr[0])): \n",
    "        print('chunk {0} ignored!'.format(ind+1))\n",
    "        ind = ind+1\n",
    "        continue\n",
    "\n",
    "    chunk = (chunk[ (chunk['day'] <= daycut_val[1]) & (chunk['day'] > daycut_tr[0])] )\n",
    "    chunk = chunk[chunk['custid'].isin(cust)]\n",
    "\n",
    "    chunk['time_hr'] = (np.rint(np.remainder(chunk['timestamp'], 3600*24)/(divide)))\n",
    "    \n",
    "    chunk = chunk.merge(bin_custid, left_on='custid',how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_custid, left_on=['custid','time_hr'], how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_grpid, left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "\n",
    "    chunk.drop(['groupid','custid'],axis=1, inplace=True)\n",
    "\n",
    "    cols = chunk.columns.tolist()\n",
    "    ncols = cols[1:]\n",
    "    ncols.append(cols[0])\n",
    "    chunk = chunk[ncols]\n",
    "\n",
    "    if(chunk['day'].min() < daycut_tr[1]): \n",
    "        chunk_tr = chunk[(chunk['day'] <= daycut_tr[1]) & (chunk['day'] > daycut_tr[0])]\n",
    "        chunk_tr.to_hdf(path+outputhead+'_train.h5','train', format='table', append=True)\n",
    "        print('    --- to train.h5')\n",
    "\n",
    "    if(chunk['day'].max() > daycut_val[0]):    \n",
    "        chunk_te = chunk[(chunk['day'] <= daycut_val[1]) & (chunk['day'] > daycut_val[0])]   \n",
    "        chunk_te.to_hdf(path+outputhead+'_test.h5','testM5', format='table', append=True)\n",
    "        print('    --- to test.h5')\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    print('chunk {0} done!'.format(ind+1))\n",
    "    ind = ind+1\n",
    "    \n",
    "print('df_train output done!')\n",
    "print('{0} rows is written in total.'.format(nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('second part: remove the validate time and apply the result to test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(file, usecols = ['custid','groupid','timestamp','invest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add time of the day column\n",
    "mintimestamp = np.min(df_train['timestamp'])\n",
    "df_train['timestamp'] = df_train['timestamp'] - mintimestamp\n",
    "df_train['day'] = np.fix(df_train['timestamp'] / 3600./24.) +1\n",
    "df_train['time_hr'] = (np.rint(np.remainder(df_train['timestamp'], 3600*24)/(divide)))\n",
    "df_train = df_train[ (df_train['day'] <= daycut_Ragg[1]) & (df_train['day'] > daycut_Ragg[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby groupid, time_hr\n",
    "grouped2 = df_train[df_train['invest']>2.0].groupby(['groupid', 'time_hr'])\n",
    "grouped10 = df_train[df_train['invest']>10.0].groupby(['groupid','time_hr'])\n",
    "grouped = df_train.groupby(['groupid', 'time_hr'])\n",
    "bin_hr_grpid = pd.DataFrame({'meanInv.grpidHr': grouped['invest'].mean().round(decimals=2), \n",
    "                             'rInvGT2.grpidHr': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                             'rInvGT10.grpidHr': (grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                             'q75Inv.grpidHr': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                             'q95Inv.grpidHr': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                             'q999Inv.grpidHr': grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get test data, use it to filter the train data, and merge. \n",
    "\n",
    "## filter the df_train, and only leave the rows with the custid appeared in the test set\n",
    " \n",
    "## groupby custid\n",
    "grouped2 = df_train[(df_train['invest']>2.0)& (df_train['invest']<10.)].groupby(['custid'])\n",
    "grouped10 = df_train[(df_train['invest']>10.0) ].groupby(['custid'])\n",
    "grouped = df_train.groupby(['custid'])\n",
    "bin_custid = pd.DataFrame({'meanInv.custid': grouped['invest'].mean().round(decimals=2), \n",
    "                           'rInvGT2.custid': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                           'rInvGT10.custid': (grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                           'q75Inv.custid': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                           'q95Inv.custid': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                           'q999Inv.custid':grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby custid and time_hr\n",
    "grouped2 = df_train[(df_train['invest']>2.0)& (df_train['invest']<10.)].groupby(['custid','time_hr'])\n",
    "grouped10 = df_train[(df_train['invest']>10.0) ].groupby(['custid', 'time_hr'])\n",
    "grouped = df_train.groupby(['custid','time_hr'])\n",
    "bin_hr_custid = pd.DataFrame({'meanInv.custidHr': grouped['invest'].mean().round(decimals=2), \n",
    "                              'rInvGT2.custidHr': (grouped2['invest'].count()/grouped['invest'].count()).round(decimals=3),\n",
    "                              'rInvGT10.custidHr':(grouped10['invest'].count()/grouped['invest'].count()).round(decimals=4),\n",
    "                              'q75Inv.custidHr': grouped['invest'].quantile(0.75).round(decimals=2), \n",
    "                              'q95Inv.custidHr': grouped['invest'].quantile(0.95).round(decimals=2), \n",
    "                              'q999Inv.custidHr': grouped['invest'].quantile(0.999).round(decimals=2)})\n",
    "del grouped2, grouped10, grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = path+\"test_data.csv\"\n",
    "df_test = pd.read_csv(file, usecols = ['custid','groupid','timestamp'], nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['timestamp'] = df_test['timestamp'] - mintimestamp\n",
    "df_test['time_hr'] = (np.rint(np.remainder(df_test['timestamp'], 3600*24)/(divide)))\n",
    "df_test['index'] = np.arange(df_test.shape[0])\n",
    "\n",
    "df_test = df_test.merge(bin_custid, left_on='custid',how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_custid, left_on=['custid','time_hr'],how='left',right_index=True)\n",
    "df_test = df_test.merge(bin_hr_grpid, left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "df_test.set_index('index',inplace=True)\n",
    "df_test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.drop(['groupid','custid'],axis=1, inplace=True)\n",
    "df_test.to_hdf(path+outputhead+'_test.h5','test2',format='table')\n",
    "print('second df_test ouput done!')\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##write out train\n",
    "\n",
    "file = path+\"test_data.csv\"\n",
    "df_test = pd.read_csv(file, usecols = ['custid'])\n",
    "cust = np.unique(df_test['custid'])\n",
    "\n",
    "## Load data\n",
    "file = path+\"train_data.csv\"\n",
    "chunksize = 40730866/10\n",
    "cols = ['custid', 'groupid','timestamp','invest']\n",
    "ind = 0\n",
    "nrows = 0\n",
    "print('daycut {0}--{1},{2}--{3}'.format(daycut_Ragg[0],\n",
    "      daycut_Ragg[1],daycut_Rtr[0],daycut_Rtr[1]))\n",
    "for chunk in pd.read_csv(file,usecols = cols,chunksize = chunksize):\n",
    "    chunk['index'] = np.arange(chunk.shape[0]) + nrows\n",
    "    nrows = nrows + chunk.shape[0]\n",
    "    chunk.set_index('index',inplace=True)\n",
    "    chunk['timestamp'] = chunk['timestamp'] - mintimestamp\n",
    "    chunk['day'] = np.fix(chunk['timestamp'] / 3600./24.) + 1\n",
    "\n",
    "    print('day range: ({0},{1})'.format(chunk['day'].min(), chunk['day'].max()))\n",
    "    if ( (chunk['day'].min() > daycut_Rtr[1]) | (chunk['day'].max() < daycut_Rtr[0])): \n",
    "        print('chunk {0} ignored!'.format(ind+1))\n",
    "        ind = ind+1\n",
    "        continue\n",
    "\n",
    "    chunk = (chunk[ (chunk['day'] <= daycut_Rtr[1]) & (chunk['day'] > daycut_Rtr[0])] )\n",
    "    chunk = chunk[chunk['custid'].isin(cust)]\n",
    "\n",
    "    chunk['time_hr'] = (np.rint(np.remainder(chunk['timestamp'], 3600*24)/(divide)))\n",
    "    \n",
    "    chunk = chunk.merge(bin_custid, left_on='custid',how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_custid, left_on=['custid','time_hr'], how='left',right_index=True)\n",
    "    chunk = chunk.merge(bin_hr_grpid, left_on=['groupid','time_hr'], how='left',right_index=True)\n",
    "\n",
    "    chunk.drop(['groupid','custid'],axis=1, inplace=True)\n",
    "\n",
    "    cols = chunk.columns.tolist()\n",
    "    ncols = cols[1:]\n",
    "    ncols.append(cols[0])\n",
    "    chunk = chunk[ncols]\n",
    "\n",
    "    if(chunk['day'].min() < daycut_Rtr[1]): \n",
    "        chunk_tr = chunk[(chunk['day'] <= daycut_Rtr[1]) & (chunk['day'] > daycut_Rtr[0])]\n",
    "        chunk_tr.to_hdf(path+outputhead+'_train.h5','train2', format='table', append=True)\n",
    "        print('    --- to train.h5')\n",
    "\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "    print('chunk {0} done!'.format(ind+1))\n",
    "    ind = ind+1\n",
    "    \n",
    "print('second df_train output done!')\n",
    "print('{0} rows is written in total.'.format(nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
