{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use data from feature_time_1h_0915\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = ''\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "from sklearn.cross_validation import KFold\n",
    "import sys\n",
    "#sys.path.append(path+'/src/python/')\n",
    "from data_load import loadHDF_train\n",
    "from data_load import loadHDF_test\n",
    "from time import time\n",
    "from sys import stdout\n",
    "from copy import deepcopy\n",
    "\n",
    "seed = 9555\n",
    "np.random.seed(seed)\n",
    "\n",
    "kfold=9\n",
    "params = {\"seed\": np.random.randint(0,1000),\n",
    "          \"eta\": 0.1,  \n",
    "          \"objective\":\"reg:linear\", \n",
    "          \"max_depth\":3, \"subsample\":0.5, \"colsample_bylevel\": 0.75, \"colsample_bytree\": 0.75, \n",
    "          \"eval_metric\": \"rmse\", \n",
    "          \"min_child_weight\": 3000, 'tree_method':'exact',\n",
    "          \"booster\":'gbtree', 'silent':1}\n",
    "early_stop = 50\n",
    "num_round = 200\n",
    "clip = [1.,50.]\n",
    "unit = 3600.*24.\n",
    "\n",
    "file = path+\"train_data.csv\"\n",
    "file_te = path+\"test_data.csv\"\n",
    "outputhead = 'feat_1hr.v3.'\n",
    "\n",
    "outputfilehead = 'xgb_M6_1hrAgg_plusEvent.CV9.ss5'\n",
    "finalsubmitfile = '0915-8_'+outputfilehead+'.havg.csv'\n",
    "datafilehead = path+'feat_1hr.v3.'\n",
    "\n",
    "print(num_round)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = [u'meanInv.custid', u'q25Inv.custid',\n",
    "       u'q50Inv.custid', u'q75Inv.custid', u'q95Inv.custid', u'q999Inv.custid',\n",
    "       u'rInvGT1.custid', u'rInvGT10.custid', u'rInvGT2.custid',\n",
    "       u'cnt.eventid', u'q25Inv.eventid', u'q50Inv.eventid', u'q75Inv.eventid',\n",
    "       u'q95Inv.eventid', u'rInvGT1.eventid', u'rInvGT10.eventid',\n",
    "       u'rInvGT2.eventid', u'meanInv.curHr', u'q75Inv.curHr', u'q95Inv.curHr',\n",
    "       u'q999Inv.curHr', u'rInvGT10.curHr', u'rInvGT2.curHr',\n",
    "       u'meanInv.pltfHr', u'q75Inv.pltfHr', u'q95Inv.pltfHr',\n",
    "       u'q999Inv.pltfHr', u'rInvGT10.pltfHr', u'rInvGT2.pltfHr',\n",
    "       u'meanInv.grpidHr', u'q75Inv.grpidHr', u'q95Inv.grpidHr',\n",
    "       u'q999Inv.grpidHr', u'rInvGT10.grpidHr', u'rInvGT2.grpidHr']\n",
    "#didn't use\n",
    "month=6\n",
    "timelimit = 3600.*24* np.array([(month-1),month])*30 \n",
    "np.random.seed(seed)\n",
    "np.random.randint(0,1000)\n",
    "\n",
    "def preprocess(d, timelimit=[0,999999999], missing=0, index = []):\n",
    "#    if(len(index) > 0):\n",
    "#        index = index[(d['timestamp'] >= timelimit[0]) & (d['timestamp'] < timelimit[1])]\n",
    "\n",
    "#    dcp = deepcopy(d[(d['timestamp'] >= timelimit[0]) & (d['timestamp'] < timelimit[1])])\n",
    "#    del d\n",
    "#    gc.collect()\n",
    "#    d.drop('timestamp', inplace=True, axis=1)\n",
    "    d.fillna(missing, inplace=True)\n",
    "    if(len(index) == 0):\n",
    "        return d\n",
    "    else:\n",
    "        return d, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## redo the training for train2, test2\n",
    "dtr2, pred2, dtr2_index = loadHDF_train(datafilehead+'train.h5', key='train', \n",
    "                                     columns = colnames)\n",
    "\n",
    "## preprocess\n",
    "dtr2, dtr2_index = preprocess(dtr2, missing=0, index=dtr2_index)\n",
    "pred2 = preprocess(pred2, missing=0)\n",
    "\n",
    "dte2, dte2_index = loadHDF_test(datafilehead+'test.h5', key='test', columns = colnames)\n",
    "dte2 = preprocess(dte2, missing=0)\n",
    "num_te2 = dte2.shape[0]\n",
    "dtest2 = xgb.DMatrix(dte2, missing=0)\n",
    "fmap = dte2.columns\n",
    "del dte2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(pred2.shape[0], n_folds=kfold, random_state=np.random.randint(0,1000))\n",
    "ptest = pd.DataFrame({'invest': np.zeros(num_te2)},index=dte2_index)\n",
    "score_list = []\n",
    "sc_val = []\n",
    "val_result = pd.DataFrame()\n",
    "featImp = pd.DataFrame({\"gain\": np.zeros(len(fmap)),\\\n",
    "                        \"fscore\": np.zeros(len(fmap))}, index = fmap)\n",
    "featImp.sort_index(inplace=True)\n",
    "for k, (tr_index, v_index) in enumerate(kf):\n",
    "    train_index = dtr2_index[tr_index]\n",
    "    val_index = dtr2_index[v_index]\n",
    "\n",
    "    m_start = time()\n",
    "    X_train, X_val = dtr2.loc[train_index], dtr2.loc[val_index]\n",
    "    y_train, y_val = pred2.loc[train_index], pred2.loc[val_index]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, missing=0)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val, missing=0)\n",
    "    \n",
    "    X_valIndex = X_val.index\n",
    "    del X_train, X_val\n",
    "    gc.collect()\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain,'train')]\n",
    "    \n",
    "    params['seed'] = np.random.randint(0,1000)    \n",
    "    model_xgb = xgb.train(params, dtrain, num_round, watchlist, \n",
    "                verbose_eval=False, maximize=False, early_stopping_rounds=early_stop)\n",
    "    \n",
    "    pred_train = model_xgb.predict(dtrain)\n",
    "    pred_val = model_xgb.predict(dvalid)\n",
    "    pred_test = model_xgb.predict(dtest2)\n",
    "\n",
    "    pred_train = np.clip(pred_train, clip[0], clip[1])\n",
    "    pred_val = np.clip(pred_val, clip[0], clip[1])\n",
    "    pred_test = np.clip(pred_test, clip[0], clip[1])\n",
    "    m_end = time()\n",
    "\n",
    "    featImp0 = pd.DataFrame({\"gain\":model_xgb.get_score(importance_type='gain'),\n",
    "                             \"fscore\":model_xgb.get_score(importance_type='weight')})\n",
    "    featImp['gain'] = featImp0['gain']/kfold + featImp['gain']\n",
    "    featImp['fscore'] = featImp0['fscore']/kfold + featImp['fscore']\n",
    "                            \n",
    "    score_train = rmse(y_train, pred_train)\n",
    "    score_val = rmse(y_val, pred_val)\n",
    "    dd = pd.DataFrame({'pred':pred_val,'invest':y_val['invest'], \n",
    "                       'fold':(np.zeros(y_val.shape[0])+k)}, \n",
    "                       index=X_valIndex)\n",
    "\n",
    "    ptest = pd.concat([ptest, pd.DataFrame({k:1./pred_test},index=dte2_index)],axis=1) \n",
    "    \n",
    "    val_result = pd.concat([val_result, dd])\n",
    "    score_list.append({'fold':k,'score_valid': score_val, \n",
    "                       'score_train': score_train, 'time':m_end-m_start})\n",
    "    sc_val.append(score_val)\n",
    "\n",
    "    print \"fold:{0}, train={1:0.3f}, val={2:0.3f}, val1={3:0.3f}, val2={4:0.3f},\\\n",
    "           proc_time={5:5.0f}\".format(k,score_train, score_val,0, 0, m_end-m_start)\n",
    "    stdout.flush()\n",
    "    del y_train, y_val, dtrain, dvalid, pred_train, pred_val, pred_test, model_xgb\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ptest.columns[1:]\n",
    "ptest['invest'] = kfold/(ptest[columns].sum(axis=1))    \n",
    "ptest = ptest['invest']\n",
    "\n",
    "## Save validate to file\n",
    "ptest.to_hdf(path+outputfilehead+'.te.h5','test', format='table')\n",
    "val_result.to_hdf(path+outputfilehead+'.tr.h5','model',format='table')\n",
    "\n",
    "score_list = pd.DataFrame(score_list)\n",
    "    \n",
    "totalTime = score_list['time'].sum() / 60.\n",
    "meanLCV = score_list['score_valid'].mean()\n",
    "stdLCV = score_list['score_valid'].std()\n",
    "\n",
    "print('num_round: {0}, early_stop: {1}'.format(num_round,early_stop))\n",
    "print(params)\n",
    "print('## Summary: score_valid mean = {0:0.5f} pm {1:0.5f} with total process time: {2:5.0f}'.\\\n",
    "      format(meanLCV, stdLCV, totalTime))\n",
    "stdout.flush()\n",
    "\n",
    "## write out submission file\n",
    "ptest.to_csv(path+finalsubmitfile,header=False,index=False)\n",
    "\n",
    "print('### feature importance')\n",
    "featImp.sort_values(by=['gain'],axis=0, ascending=False, inplace=True)\n",
    "print(featImp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featImp.to_csv(path+outputfilehead+'.xgbfeatImp.1.csv')\n",
    "\n",
    "del dtr2, dtr2_index, pred2, dte2_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
