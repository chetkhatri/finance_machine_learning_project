{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = ''\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "from sklearn.cross_validation import KFold\n",
    "import sys\n",
    "#sys.path.append(path+'/src/python/')\n",
    "from data_load import loadHDF_train\n",
    "from data_load import loadHDF_test\n",
    "from time import time\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 555#555\n",
    "kfold= 5\n",
    "params = {\"seed\": np.random.randint(0,1000),\n",
    "          \"eta\": 0.1,  \n",
    "          \"objective\":\"reg:linear\", \n",
    "          \"max_depth\":3, \"subsample\":0.5, \"colsample_bylevel\": 0.5, \"colsample_bytree\": 0.5, \n",
    "          \"eval_metric\": \"rmse\", \n",
    "          \"gamma\": 0., \n",
    "          \"booster\":'gbtree', 'silent':1}\n",
    "num_round = 200\n",
    "clip = [1.,50.]\n",
    "outputfilehead = 'xgb_1hrAgg'\n",
    "finalsubmitfile = '0907_'+outputfilehead+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = [u'timestamp', u'time_hr', u'meanInv.custid', u'q75Inv.custid', u'q95Inv.custid',\n",
    "            u'q999Inv.custid', u'rInvGT10.custid', u'rInvGT2.custid',\n",
    "            u'meanInv.curHr', u'q75Inv.curHr', u'q95Inv.curHr', u'q999Inv.curHr',\n",
    "            u'rInvGT10.curHr', u'rInvGT2.curHr', u'meanInv.pltfHr',\n",
    "            u'q75Inv.pltfHr', u'q95Inv.pltfHr', u'q999Inv.pltfHr',\n",
    "            u'rInvGT10.pltfHr', u'rInvGT2.pltfHr', u'meanInv.grpidHr',\n",
    "            u'q75Inv.grpidHr', u'q95Inv.grpidHr', u'q999Inv.grpidHr',\n",
    "            u'rInvGT10.grpidHr', u'rInvGT2.grpidHr']\n",
    "datafilehead = path + 'feat_1hr_'\n",
    "timelimit = 3600.*24*np.array([153,183]) # last 30 days \n",
    "np.random.seed(seed)\n",
    "np.random.randint(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(d, timelimit=[0,999999], missing=0, index = []):\n",
    "    if(len(index) > 0):\n",
    "        index = index[(d['timestamp'] >= timelimit[0]) & (d['timestamp'] < timelimit[1])]\n",
    "        d = d[(d['timestamp'] >= timelimit[0]) & (d['timestamp'] < timelimit[1])]\n",
    "\n",
    "    d.drop('timestamp', inplace=True, axis=1)\n",
    "    d.fillna(missing, inplace=True)\n",
    "    if(len(index) == 0):\n",
    "        return d\n",
    "    else:\n",
    "        return d, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr, pred, dtr_index = loadHDF_train(datafilehead+'train.h5', key='train', \n",
    "                                     selection = 'index > {0}'.format(35730865), columns = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print pred # investment in training data\n",
    "#print dtr # training data frame\n",
    "#print dtr_index #training data index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## preprocess\n",
    "dtr, dtr_index = preprocess(dtr, timelimit = timelimit, missing=0, index=dtr_index)\n",
    "pred = preprocess(pred, timelimit, missing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dte, dte_index = loadHDF_test(datafilehead+'test.h5', key='test', columns = colnames)\n",
    "dte = preprocess(dte, missing=0)\n",
    "num_te = dte.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print dte # test data frame\n",
    "#print dte_index #test data index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(dte, missing=0)\n",
    "del dte\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv1, ans_dval1, dval1_index = loadHDF_train(datafilehead+'train_val1.h5', key='val1', columns = colnames)\n",
    "dv1 = preprocess(dv1, missing=0)\n",
    "ans_dval1 = preprocess(ans_dval1, missing=0)\n",
    "num_dval1 = dv1.shape[0]\n",
    "dval1 = xgb.DMatrix(dv1, missing=0)\n",
    "\n",
    "dv2, ans_dval2, dval2_index = loadHDF_train(datafilehead+'train_val2.h5', key='val2', columns = colnames)\n",
    "dv2 = preprocess(dv2, missing=0)\n",
    "ans_dval2 = preprocess(ans_dval2, missing=0)\n",
    "num_dval2 = dv2.shape[0]\n",
    "dval2 = xgb.DMatrix(dv2, missing=0)\n",
    "del dv2, dv1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(pred.shape[0], n_folds=kfold, random_state=np.random.randint(0,1000))\n",
    "val_result = pd.DataFrame()\n",
    "val1_result = pd.DataFrame({'invest': ans_dval1['invest']}, index=ans_dval1.index)\n",
    "val2_result = pd.DataFrame({'invest': ans_dval2['invest']}, index=ans_dval2.index)\n",
    "ptest = pd.DataFrame({'invest': np.zeros(num_te)},index=dte_index)\n",
    "score_list = []\n",
    "sc_val = []\n",
    "\n",
    "for k, (tr_index, v_index) in enumerate(kf):\n",
    "    train_index = dtr_index[tr_index]\n",
    "    val_index = dtr_index[v_index]\n",
    "\n",
    "    m_start = time()\n",
    "    X_train, X_val = dtr.loc[train_index], dtr.loc[val_index]\n",
    "    y_train, y_val = pred.loc[train_index], pred.loc[val_index]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, missing=0)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val, missing=0)\n",
    "    \n",
    "    X_valIndex = X_val.index\n",
    "    del X_train, X_val\n",
    "    gc.collect()\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain,'train')]\n",
    "    \n",
    "    params['seed'] = np.random.randint(0,1000)    \n",
    "    model_xgb = xgb.train(params, dtrain, num_round, watchlist, verbose_eval=False, maximize=False)\n",
    "    \n",
    "    pred_train = model_xgb.predict(dtrain)\n",
    "    pred_val = model_xgb.predict(dvalid)\n",
    "    pred_test = model_xgb.predict(dtest)\n",
    "\n",
    "    \n",
    "    pred_train = np.clip(pred_train, clip[0], clip[1])\n",
    "    pred_val = np.clip(pred_val, clip[0], clip[1])\n",
    "    pred_test = np.clip(pred_test, clip[0], clip[1])\n",
    "    \n",
    "    m_end = time()\n",
    "    \n",
    "    score_train = rmse(y_train, pred_train)\n",
    "    score_val = rmse(y_val, pred_val)\n",
    "    dd = pd.DataFrame({'pred':pred_val,'invest':y_val['invest'], \n",
    "                       'fold':(np.zeros(y_val.shape[0])+k)},index=X_valIndex)\n",
    "\n",
    "    ptest = pd.concat([ptest, pd.DataFrame({k:1./pred_test},index=dte_index)],axis=1) \n",
    "\n",
    "    pred_dval1 = model_xgb.predict(dval1)\n",
    "    pred_dval1 = np.clip(pred_dval1, clip[0], clip[1])\n",
    "    score_dval1 = rmse(ans_dval1, pred_dval1)\n",
    "    val1_result = pd.concat([val1_result, pd.DataFrame({k:1./pred_dval1})],axis=1) \n",
    "\n",
    "    pred_dval2 = model_xgb.predict(dval2)\n",
    "    pred_dval2 = np.clip(pred_dval2, clip[0], clip[1])\n",
    "    score_dval2 = rmse(ans_dval2, pred_dval2)\n",
    "    val2_result = pd.concat([val2_result, pd.DataFrame({k:1./pred_dval2})],axis=1) \n",
    "\n",
    "    \n",
    "    val_result = pd.concat([val_result, dd])\n",
    "    score_list.append({'fold':k,'score_valid': score_val, \n",
    "                       'score_val1': score_dval1, 'score_val2': score_dval2, \n",
    "                       'score_train': score_train, 'time':m_end-m_start})\n",
    "    sc_val.append(score_val)\n",
    "\n",
    "    print \"fold:{0}, train={1:0.3f}, val={2:0.3f}, val1={3:0.3f}, val2={4:0.3f}, proc_time={5:5.0f}\".format(k,score_train, score_val,score_dval1, score_dval2, m_end-m_start)\n",
    "    stdout.flush()\n",
    "    del y_train, y_val, dtrain, dvalid, pred_train, pred_val, pred_test, model_xgb\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ptest.columns[1:]\n",
    "ptest['invest'] = kfold/(ptest[columns].sum(axis=1))    \n",
    "ptest = ptest['invest']\n",
    "\n",
    "## Save validate to file\n",
    "ptest.to_hdf(path+outputfilehead+'.te.h5','test', format='table')\n",
    "val_result.to_hdf(path+outputfilehead+'.tr.h5','model',format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## print out result statistics\n",
    "# score_list = pd.DataFrame(score_list)\n",
    "    \n",
    "# totalTime = score_list['time'].sum() / 60.\n",
    "# meanLCV = score_list['score_valid'].mean()\n",
    "# stdLCV = score_list['score_valid'].std()\n",
    "# print(params)\n",
    "# print('### Summary: score_valid mean = {0:0.5f} pm {1:0.5f} with total process time: {2:5.0f}'.format(meanLCV, stdLCV, totalTime))\n",
    "# print('')\n",
    "# print('')\n",
    "# stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out submission file\n",
    "ptest.to_csv(path+finalsubmitfile,header=False,index=False)\n",
    "\n",
    "# ## save val1 and val2\n",
    "# columns = val1_result.columns[1:]\n",
    "# val1_result['pred'] = kfold/(val1_result[columns].sum(axis=1))    \n",
    "# val1_result = val1_result[['invest','pred']]\n",
    "# val1_result.to_hdf(path+outputfilehead+'.trval.h5','val1', format='table')\n",
    "\n",
    "# val2_result['pred'] = kfold/(val2_result[columns].sum(axis=1))    \n",
    "# val2_result = val2_result[['invest','pred']]\n",
    "# val2_result.to_hdf(path+outputfilehead+'.trval.h5','val2', format='table')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptest.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
